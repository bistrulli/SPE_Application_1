{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4: M/M/1 Model Validation on Kubernetes\n",
    "## Theoretical Predictions vs Real Cloud-Native System Measurements\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Estimate service rate from real K8s system measurements using Istio metrics\n",
    "- Validate M/M/1 theoretical formulas against measured cloud-native metrics\n",
    "- Analyze model accuracy under varying load conditions on Kubernetes\n",
    "- Understand practical deviations from theoretical predictions in service mesh environment\n",
    "- Compare single vs multi-replica scaling behavior\n",
    "\n",
    "---\n",
    "\n",
    "## Methodology\n",
    "\n",
    "### Service Rate Estimation Strategy for K8s\n",
    "\n",
    "Instead of estimating service rate from individual response times, we use cloud-native metrics:\n",
    "\n",
    "1. **Calibration Campaign**: Run controlled experiment with known load on K8s\n",
    "2. **Collect Istio Metrics**: Measure utilization and throughput via Prometheus + Istio telemetry\n",
    "3. **Calculate Service Rate**: Œº = throughput / utilization (using native K8s CPU metrics)\n",
    "4. **Validation Experiments**: Test multiple load conditions using estimated Œº\n",
    "5. **Scaling Analysis**: Compare single vs multi-replica performance\n",
    "\n",
    "This approach leverages cloud-native observability to provide robust service rate estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites and Setup\n",
    "\n",
    "This notebook requires a Kubernetes cluster with Istio service mesh and Prometheus monitoring. Follow these steps to set up your environment:\n",
    "\n",
    "### Required Components\n",
    "\n",
    "1. **Kubernetes Cluster**\n",
    "   - Minikube, kind, or any K8s cluster with sufficient resources (4+ GB RAM recommended)\n",
    "   - `kubectl` configured and connected to your cluster\n",
    "\n",
    "2. **Helm Package Manager**\n",
    "   ```bash\n",
    "   # Install Helm (if not already installed)\n",
    "   curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\n",
    "   ```\n",
    "\n",
    "3. **Istio Service Mesh**\n",
    "   ```bash\n",
    "   # Download and install Istio\n",
    "   curl -L https://istio.io/downloadIstio | sh -\n",
    "   export PATH=\"$PWD/istio-*/bin:$PATH\"\n",
    "   \n",
    "   # Install Istio with default configuration\n",
    "   istioctl install --set values.defaultRevision=default -y\n",
    "   \n",
    "   # Enable sidecar injection for our namespace\n",
    "   kubectl create namespace spe-system\n",
    "   kubectl label namespace spe-system istio-injection=enabled\n",
    "   ```\n",
    "\n",
    "4. **kube-prometheus-stack (Prometheus + Grafana)**\n",
    "   ```bash\n",
    "   # Add Prometheus community Helm repository\n",
    "   helm repo add prometheus-community https://prometheus-community.github.io/helm-charts\n",
    "   helm repo update\n",
    "   \n",
    "   # Install kube-prometheus-stack\n",
    "   helm install prometheus prometheus-community/kube-prometheus-stack \\\n",
    "     --namespace monitoring \\\n",
    "     --create-namespace \\\n",
    "     --set prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false \\\n",
    "     --set prometheus.prometheusSpec.podMonitorSelectorNilUsesHelmValues=false\n",
    "   ```\n",
    "\n",
    "### Quick Setup Script\n",
    "\n",
    "For a rapid local setup using minikube:\n",
    "\n",
    "```bash\n",
    "# Start minikube with sufficient resources\n",
    "minikube start --memory=6144 --cpus=4\n",
    "\n",
    "# Install all components\n",
    "./setup-k8s-environment.sh\n",
    "```\n",
    "\n",
    "### Verification\n",
    "\n",
    "After installation, verify all components are running:\n",
    "\n",
    "```bash\n",
    "# Check Istio\n",
    "kubectl get pods -n istio-system\n",
    "\n",
    "# Check Prometheus stack\n",
    "kubectl get pods -n monitoring\n",
    "\n",
    "# Check if ServiceMonitor CRDs are available\n",
    "kubectl get crd servicemonitors.monitoring.coreos.com\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**‚ö†Ô∏è Important Notes:**\n",
    "- This setup may take 10-15 minutes depending on your internet connection\n",
    "- Ensure your K8s cluster has sufficient resources (minimum 4GB RAM, 2 CPU cores)\n",
    "- The notebook will automatically handle port-forwarding and service discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Verification\n",
    "\n",
    "Verify that all required components are properly installed and configured before proceeding with experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All dependencies imported successfully\n",
      "üìã Available modules:\n",
      "  - K8sManager: Kubernetes deployment and management\n",
      "  - MM1Theoretical: M/M/1 theoretical calculations\n",
      "  - K8sPrometheusCollector: NEW working K8s metrics collector\n",
      "  - AsyncWorkloadGenerator: Load testing and workload generation\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS AND DEPENDENCIES\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import subprocess\n",
    "import shutil\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "# Import SPE modules\n",
    "from k8s_utils import K8sManager, get_istio_queries\n",
    "from mm1_theoretical import MM1Theoretical\n",
    "from k8s_prometheus_collector import K8sPrometheusCollector  # NEW WORKING COLLECTOR!\n",
    "from workload_generator import AsyncWorkloadGenerator\n",
    "\n",
    "print(\"‚úÖ All dependencies imported successfully\")\n",
    "print(\"üìã Available modules:\")\n",
    "print(\"  - K8sManager: Kubernetes deployment and management\")\n",
    "print(\"  - MM1Theoretical: M/M/1 theoretical calculations\")  \n",
    "print(\"  - K8sPrometheusCollector: NEW working K8s metrics collector\")\n",
    "print(\"  - AsyncWorkloadGenerator: Load testing and workload generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K8s Experiment Configuration (kube-prometheus-stack):\n",
      "  Prometheus: prometheus-kube-prometheus-prometheus in monitoring namespace\n",
      "  Calibration: Œª=3.0 req/s, duration=300.0s\n",
      "  Validation: 4 utilization levels, 180s each\n",
      "  Scaling: 3 replica configurations, 120s each\n",
      "  Total estimated time: 23.0 minutes\n",
      "Configuration complete\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# K8S EXPERIMENT CONFIGURATION PARAMETERS\n",
    "# =============================================================================\n",
    "\n",
    "# K8s infrastructure\n",
    "K8S_NAMESPACE = \"spe-system\"\n",
    "K8S_MANIFESTS_DIR = \"k8s-manifests\"\n",
    "\n",
    "# kube-prometheus-stack configuration\n",
    "PROMETHEUS_NAMESPACE = \"monitoring\"\n",
    "PROMETHEUS_SERVICE = \"prometheus-kube-prometheus-prometheus\"\n",
    "PROMETHEUS_URL = \"http://localhost:9090\"\n",
    "\n",
    "# Calibration experiment parameters\n",
    "CALIBRATION_LAMBDA = 3.0      # Conservative arrival rate for calibration\n",
    "CALIBRATION_DURATION = 300.0  # Duration of calibration experiment (seconds)\n",
    "CALIBRATION_WARMUP = 60.0     # Warmup period to reach steady state\n",
    "\n",
    "# Validation experiment parameters  \n",
    "TARGET_UTILIZATIONS = [0.2, 0.4, 0.7]  # Multiple utilization levels\n",
    "VALIDATION_DURATION = 180     # Duration per validation experiment (seconds)\n",
    "VALIDATION_WARMUP = 60        # Warmup period per validation experiment\n",
    "VALIDATION_COOLDOWN = 120      # Cooldown period between experiments\n",
    "\n",
    "# Scaling experiment parameters\n",
    "REPLICA_PLAN = [1, 2, 3]      # Pod replica counts to test\n",
    "SCALING_TEST_LAMBDA = 8.0     # Fixed arrival rate for scaling tests\n",
    "SCALING_DURATION = 120        # Duration per scaling test\n",
    "SCALING_SETTLE_TIME = 30      # Wait time after scaling\n",
    "\n",
    "# Metrics collection parameters\n",
    "METRICS_STEP = \"5s\"           # Prometheus query resolution\n",
    "CORE_METRICS = ['throughput', 'cpu_usage', 'response_time_avg']\n",
    "\n",
    "print(\"K8s Experiment Configuration (kube-prometheus-stack):\")\n",
    "print(f\"  Prometheus: {PROMETHEUS_SERVICE} in {PROMETHEUS_NAMESPACE} namespace\")\n",
    "print(f\"  Calibration: Œª={CALIBRATION_LAMBDA} req/s, duration={CALIBRATION_DURATION}s\")\n",
    "print(f\"  Validation: {len(TARGET_UTILIZATIONS)} utilization levels, {VALIDATION_DURATION}s each\")\n",
    "print(f\"  Scaling: {len(REPLICA_PLAN)} replica configurations, {SCALING_DURATION}s each\")\n",
    "total_time = (CALIBRATION_DURATION + len(TARGET_UTILIZATIONS) * VALIDATION_DURATION + len(REPLICA_PLAN) * SCALING_DURATION) / 60\n",
    "print(f\"  Total estimated time: {total_time:.1f} minutes\")\n",
    "print(\"Configuration complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K8s Infrastructure Setup (kube-prometheus-stack)\n",
      "==================================================\n",
      "‚ö†Ô∏è Warning: Environment verification not run\n",
      "üí° Please run the environment verification cell first for best results\n",
      "üîÑ Continuing with infrastructure setup anyway...\n",
      "\n",
      "‚úÖ kubectl available\n",
      "\n",
      "üèóÔ∏è Creating namespace spe-system FIRST...\n",
      "‚úÖ Namespace spe-system already exists\n",
      "üîß Enabling Istio injection on spe-system...\n",
      "‚úÖ Istio injection enabled on spe-system\n",
      "\n",
      "üîç Verifying namespace spe-system exists...\n",
      "‚úÖ Namespace spe-system verified and ready\n",
      "\n",
      "üßπ Cleaning up old ServiceMonitors...\n",
      "‚úÖ Cleaned up old ServiceMonitors\n",
      "\n",
      "üöÄ Deploying manifests from k8s-manifests/...\n",
      "üöÄ Deploying K8s manifests from k8s-manifests/...\n",
      "‚úÖ Manifests applied successfully\n",
      "gateway.networking.istio.io/mm1-gateway unchanged\n",
      "virtualservice.networking.istio.io/mm1-virtualservice unchanged\n",
      "destinationrule.networking.istio.io/mm1-destinationrule unchanged\n",
      "peerauthentication.security.istio.io/mm1-peer-auth unchanged\n",
      "telemetry.telemetry.istio.io/mm1-telemetry unchanged\n",
      "deployment.apps/mm1-server configured\n",
      "service/mm1-server unchanged\n",
      "namespace/spe-system unchanged\n",
      "servicemonitor.monitoring.coreos.com/istio-proxy-metrics unchanged\n",
      "prometheusrule.monitoring.coreos.com/mm1-performance-rules unchanged\n",
      "\n",
      "‚è≥ Waiting for deployment rollout...\n",
      "‚úÖ Deployment rollout completed\n",
      "‚úÖ Manifests deployed successfully\n",
      "\n",
      "üìä Verifying monitoring configuration...\n",
      "‚úÖ ServiceMonitors configured:\n",
      "  - istio-proxy-metrics\n",
      "\n",
      "üîç Checking pod status...\n",
      "üìä Pod status: 1/1 ready\n",
      "\n",
      "üåê Setting up networking...\n",
      "üéØ Using external gateway: http://34.31.117.144\n",
      "\n",
      "üìä Setting up Prometheus port-forward (kube-prometheus-stack)...\n",
      "üîó Setting up port-forward: localhost:9090 -> prometheus-kube-prometheus-prometheus:9090\n",
      "‚úÖ Port-forward established successfully\n",
      "\n",
      "üîç Testing service connectivity...\n",
      "‚úÖ Service reachable: 0.282s (Success (200))\n",
      "üîç Testing Prometheus connectivity...\n",
      "‚úÖ Prometheus reachable: 0.390s\n",
      "\n",
      "üéâ K8s infrastructure setup complete!\n",
      "üìã Summary:\n",
      "  - Namespace: spe-system (with Istio injection)\n",
      "  - M/M/1 Service: http://34.31.117.144\n",
      "  - Prometheus: http://localhost:9090 (connected)\n",
      "  - Monitoring: kube-prometheus-stack in monitoring namespace\n",
      "  - Metrics: Istio proxy metrics only (no application /metrics endpoint)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# K8S INFRASTRUCTURE DEPLOYMENT\n",
    "# =============================================================================\n",
    "\n",
    "def setup_k8s_infrastructure():\n",
    "    \"\"\"\n",
    "    Deploy and configure K8s infrastructure for M/M/1 experiments.\n",
    "    Uses kube-prometheus-stack for monitoring.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (k8s_manager, mm1_url, prometheus_ready)\n",
    "    \"\"\"\n",
    "    print(\"K8s Infrastructure Setup (kube-prometheus-stack)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check if environment verification was run\n",
    "    try:\n",
    "        if not environment_status.get('prometheus', False):\n",
    "            print(\"‚ö†Ô∏è Warning: kube-prometheus-stack might not be available\")\n",
    "            print(\"üìã Environment status:\", environment_status)\n",
    "            print(\"üîÑ Continuing anyway, but monitoring may not work properly...\")\n",
    "            print(\"üí° Make sure to run the environment verification cell first\\n\")\n",
    "    except NameError:\n",
    "        print(\"‚ö†Ô∏è Warning: Environment verification not run\")\n",
    "        print(\"üí° Please run the environment verification cell first for best results\")\n",
    "        print(\"üîÑ Continuing with infrastructure setup anyway...\\n\")\n",
    "    \n",
    "    # Check kubectl availability FIRST\n",
    "    try:\n",
    "        result = subprocess.run(['kubectl', 'version', '--client'], \n",
    "                              capture_output=True, text=True, timeout=10)\n",
    "        if result.returncode != 0:\n",
    "            raise Exception(\"kubectl not available - cannot proceed\")\n",
    "        print(\"‚úÖ kubectl available\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"kubectl not available: {e}\")\n",
    "    \n",
    "    # Setup namespace with proper configuration BEFORE any deployment\n",
    "    print(f\"\\nüèóÔ∏è Creating namespace {K8S_NAMESPACE} FIRST...\")\n",
    "    try:\n",
    "        # Create namespace \n",
    "        ns_create_result = subprocess.run([\n",
    "            'kubectl', 'create', 'namespace', K8S_NAMESPACE\n",
    "        ], capture_output=True, text=True, timeout=30)\n",
    "        \n",
    "        if ns_create_result.returncode == 0:\n",
    "            print(f\"‚úÖ Namespace {K8S_NAMESPACE} created\")\n",
    "        elif \"already exists\" in ns_create_result.stderr:\n",
    "            print(f\"‚úÖ Namespace {K8S_NAMESPACE} already exists\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Namespace creation issue: {ns_create_result.stderr}\")\n",
    "            print(\"üîÑ Continuing anyway...\")\n",
    "        \n",
    "        # Enable Istio injection IMMEDIATELY after namespace creation\n",
    "        print(f\"üîß Enabling Istio injection on {K8S_NAMESPACE}...\")\n",
    "        label_result = subprocess.run([\n",
    "            'kubectl', 'label', 'namespace', K8S_NAMESPACE, \n",
    "            'istio-injection=enabled', '--overwrite'\n",
    "        ], capture_output=True, text=True, timeout=30)\n",
    "        \n",
    "        if label_result.returncode == 0:\n",
    "            print(f\"‚úÖ Istio injection enabled on {K8S_NAMESPACE}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Istio labeling issue: {label_result.stderr}\")\n",
    "            print(\"üîÑ Continuing anyway...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Namespace setup error: {e}\")\n",
    "        print(\"üîÑ Attempting to continue with deployment...\")\n",
    "    \n",
    "    # Verify namespace exists before proceeding\n",
    "    print(f\"\\nüîç Verifying namespace {K8S_NAMESPACE} exists...\")\n",
    "    try:\n",
    "        verify_result = subprocess.run([\n",
    "            'kubectl', 'get', 'namespace', K8S_NAMESPACE\n",
    "        ], capture_output=True, text=True, timeout=30)\n",
    "        \n",
    "        if verify_result.returncode == 0:\n",
    "            print(f\"‚úÖ Namespace {K8S_NAMESPACE} verified and ready\")\n",
    "        else:\n",
    "            raise Exception(f\"Namespace {K8S_NAMESPACE} does not exist: {verify_result.stderr}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Cannot proceed without namespace: {e}\")\n",
    "    \n",
    "    # Initialize K8s manager AFTER namespace setup\n",
    "    k8s = K8sManager(namespace=K8S_NAMESPACE)\n",
    "    \n",
    "    # Clean up any existing problematic ServiceMonitors\n",
    "    print(f\"\\nüßπ Cleaning up old ServiceMonitors...\")\n",
    "    try:\n",
    "        cleanup_result = subprocess.run([\n",
    "            'kubectl', 'delete', 'servicemonitor', 'mm1-server-metrics', \n",
    "            '-n', K8S_NAMESPACE, '--ignore-not-found=true'\n",
    "        ], capture_output=True, text=True, timeout=30)\n",
    "        \n",
    "        if cleanup_result.returncode == 0:\n",
    "            print(\"‚úÖ Cleaned up old ServiceMonitors\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è ServiceMonitor cleanup warning: {cleanup_result.stderr}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è ServiceMonitor cleanup warning: {e}\")\n",
    "    \n",
    "    # NOW deploy manifests (namespace exists)\n",
    "    print(f\"\\nüöÄ Deploying manifests from {K8S_MANIFESTS_DIR}/...\")\n",
    "    if not k8s.deploy_manifests(K8S_MANIFESTS_DIR):\n",
    "        raise Exception(\"K8s deployment failed\")\n",
    "    print(\"‚úÖ Manifests deployed successfully\")\n",
    "    \n",
    "    # Verify ServiceMonitor configuration\n",
    "    print(f\"\\nüìä Verifying monitoring configuration...\")\n",
    "    try:\n",
    "        # Check ServiceMonitors\n",
    "        sm_result = subprocess.run([\n",
    "            'kubectl', 'get', 'servicemonitor', '-n', K8S_NAMESPACE\n",
    "        ], capture_output=True, text=True, timeout=30)\n",
    "        \n",
    "        if sm_result.returncode == 0:\n",
    "            print(\"‚úÖ ServiceMonitors configured:\")\n",
    "            for line in sm_result.stdout.strip().split('\\n')[1:]:  # Skip header\n",
    "                if line.strip():\n",
    "                    sm_name = line.split()[0]\n",
    "                    print(f\"  - {sm_name}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è ServiceMonitor check warning: {sm_result.stderr}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è ServiceMonitor verification warning: {e}\")\n",
    "    \n",
    "    # Check pod readiness\n",
    "    print(\"\\nüîç Checking pod status...\")\n",
    "    pod_status = k8s.get_pod_status()\n",
    "    if 'error' in pod_status:\n",
    "        raise Exception(f\"Pod status check failed: {pod_status['error']}\")\n",
    "    \n",
    "    print(f\"üìä Pod status: {pod_status['ready_pods']}/{pod_status['total_pods']} ready\")\n",
    "    if pod_status['ready_pods'] == 0:\n",
    "        raise Exception(\"No ready pods found\")\n",
    "    \n",
    "    # Setup networking\n",
    "    print(\"\\nüåê Setting up networking...\")\n",
    "    gateway_ip = k8s.get_gateway_ip()\n",
    "    \n",
    "    if gateway_ip and gateway_ip != \"localhost\":\n",
    "        mm1_url = f\"http://{gateway_ip}\"\n",
    "        print(f\"üéØ Using external gateway: {mm1_url}\")\n",
    "    else:\n",
    "        # Setup gateway port-forward\n",
    "        print(\"üîó Setting up gateway port-forward...\")\n",
    "        gateway_ready = k8s.setup_port_forward(\n",
    "            service=\"istio-ingressgateway\",\n",
    "            local_port=8080,\n",
    "            service_port=80,\n",
    "            namespace=\"istio-system\"\n",
    "        )\n",
    "        if not gateway_ready:\n",
    "            raise Exception(\"Gateway port-forward failed\")\n",
    "        \n",
    "        mm1_url = \"http://localhost:8080\"\n",
    "        print(f\"üéØ Using port-forward: {mm1_url}\")\n",
    "    \n",
    "    # Setup Prometheus port-forward (kube-prometheus-stack)\n",
    "    print(f\"\\nüìä Setting up Prometheus port-forward (kube-prometheus-stack)...\")\n",
    "    prometheus_ready = k8s.setup_port_forward(\n",
    "        service=PROMETHEUS_SERVICE,\n",
    "        local_port=9090,\n",
    "        service_port=9090,\n",
    "        namespace=PROMETHEUS_NAMESPACE\n",
    "    )\n",
    "    \n",
    "    if not prometheus_ready:\n",
    "        print(\"‚ö†Ô∏è Prometheus port-forward failed - trying alternative service names...\")\n",
    "        # Try alternative service names for kube-prometheus-stack\n",
    "        alternative_services = [\n",
    "            \"prometheus-prometheus-kube-prometheus-prometheus\",\n",
    "            \"kube-prometheus-stack-prometheus\",\n",
    "            \"prometheus-server\"\n",
    "        ]\n",
    "        \n",
    "        for alt_service in alternative_services:\n",
    "            print(f\"üîó Trying service name: {alt_service}\")\n",
    "            prometheus_ready = k8s.setup_port_forward(\n",
    "                service=alt_service,\n",
    "                local_port=9090,\n",
    "                service_port=9090,\n",
    "                namespace=PROMETHEUS_NAMESPACE\n",
    "            )\n",
    "            if prometheus_ready:\n",
    "                print(f\"‚úÖ Connected using service: {alt_service}\")\n",
    "                break\n",
    "    \n",
    "    # Test connectivity\n",
    "    print(\"\\nüîç Testing service connectivity...\")\n",
    "    success, response_time, message = k8s.test_service_connectivity(mm1_url)\n",
    "    if not success:\n",
    "        raise Exception(f\"Service connectivity test failed: {message}\")\n",
    "    \n",
    "    print(f\"‚úÖ Service reachable: {response_time:.3f}s ({message})\")\n",
    "    \n",
    "    # Test Prometheus connectivity\n",
    "    if prometheus_ready:\n",
    "        print(\"üîç Testing Prometheus connectivity...\")\n",
    "        try:\n",
    "            prometheus_success, prometheus_time, prometheus_message = k8s.test_service_connectivity(PROMETHEUS_URL + \"/api/v1/query?query=up\")\n",
    "            if prometheus_success:\n",
    "                print(f\"‚úÖ Prometheus reachable: {prometheus_time:.3f}s\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Prometheus connectivity issue: {prometheus_message}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Prometheus test failed: {e}\")\n",
    "    else:\n",
    "        print(\"‚ùå Could not establish Prometheus port-forward\")\n",
    "        print(\"üí° Check if kube-prometheus-stack is properly installed:\")\n",
    "        print(\"   kubectl get svc -n monitoring | grep prometheus\")\n",
    "    \n",
    "    print(\"\\nüéâ K8s infrastructure setup complete!\")\n",
    "    print(f\"üìã Summary:\")\n",
    "    print(f\"  - Namespace: {K8S_NAMESPACE} (with Istio injection)\")\n",
    "    print(f\"  - M/M/1 Service: {mm1_url}\")\n",
    "    print(f\"  - Prometheus: {PROMETHEUS_URL} {'(connected)' if prometheus_ready else '(connection issues)'}\")\n",
    "    print(f\"  - Monitoring: kube-prometheus-stack in {PROMETHEUS_NAMESPACE} namespace\")\n",
    "    print(f\"  - Metrics: Istio proxy metrics only (no application /metrics endpoint)\")\n",
    "    \n",
    "    return k8s, mm1_url, prometheus_ready\n",
    "\n",
    "# Execute infrastructure setup\n",
    "k8s_manager, mm1_service_url, prometheus_available = setup_k8s_infrastructure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service Rate Calibration Campaign\n",
    "\n",
    "Run a controlled experiment to estimate the service rate of our M/M/1 system using K8s and Istio metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K8s Service Rate Calibration Campaign (NEW COLLECTOR)\n",
      "====================================================\n",
      "Calibration parameters:\n",
      "  Target arrival rate: 3.0 req/s\n",
      "  Experiment duration: 300.0 seconds\n",
      "  Warmup period: 60.0 seconds\n",
      "  Measurement period: 240.0 seconds\n",
      "  Service endpoint: http://34.31.117.144\n",
      "\n",
      "‚úÖ Prometheus connectivity confirmed with NEW collector\n",
      "\n",
      "Starting K8s calibration experiment...\n",
      "This will take approximately 4 minutes\n",
      "\n",
      "üöÄ Running calibration workload...\n",
      "Starting ASYNC workload generation:\n",
      "  Target rate: 3.0 req/s\n",
      "  Duration: 300.0 seconds\n",
      "  URL: http://34.31.117.144/\n",
      "  Scheduled 918 requests\n",
      "  Scheduled 50 requests, rate: 2.56 req/s\n",
      "  Scheduled 100 requests, rate: 2.70 req/s\n",
      "  Scheduled 150 requests, rate: 2.86 req/s\n",
      "  Scheduled 200 requests, rate: 3.05 req/s\n",
      "  Scheduled 250 requests, rate: 2.99 req/s\n",
      "  Scheduled 300 requests, rate: 3.01 req/s\n",
      "  Scheduled 350 requests, rate: 2.96 req/s\n",
      "  Scheduled 400 requests, rate: 2.98 req/s\n",
      "  Scheduled 450 requests, rate: 2.98 req/s\n",
      "  Scheduled 500 requests, rate: 3.06 req/s\n",
      "  Scheduled 550 requests, rate: 3.02 req/s\n",
      "  Scheduled 600 requests, rate: 2.99 req/s\n",
      "  Scheduled 650 requests, rate: 3.05 req/s\n",
      "  Scheduled 700 requests, rate: 3.05 req/s\n",
      "  Scheduled 750 requests, rate: 3.04 req/s\n",
      "  Scheduled 800 requests, rate: 3.08 req/s\n",
      "  Scheduled 850 requests, rate: 3.07 req/s\n",
      "  Scheduled 900 requests, rate: 3.07 req/s\n",
      "  Waiting for all requests to complete...\n",
      "\n",
      "Async workload completed:\n",
      "  Total requests: 918\n",
      "  Actual rate: 3.06 req/s\n",
      "  Success rate: 100.00%\n",
      "  Inter-arrival times: 917\n",
      "\n",
      "üìä Collecting K8s/Istio metrics with NEW collector...\n",
      "\n",
      "üìä Collecting K8s metrics: ['throughput', 'cpu_usage']\n",
      "üìÖ Time range: Wed Oct 22 06:07:12 2025 to Wed Oct 22 06:11:13 2025\n",
      "üîç Querying: sum(rate(istio_requests_total{destination_service_... from Wed Oct 22 06:07:12 2025 to Wed Oct 22 06:11:13 2025\n",
      "üìä Found 1 metric series\n",
      "‚úÖ Collected 49 data points, range: 2.7333 - 3.4222\n",
      "‚úÖ throughput: 49 points, mean=3.1256\n",
      "üîç Querying: sum(rate(container_cpu_usage_seconds_total{pod=~\"m... from Wed Oct 22 06:07:12 2025 to Wed Oct 22 06:11:13 2025\n",
      "üìä Found 1 metric series\n",
      "‚úÖ Collected 49 data points, range: 0.2445 - 0.3756\n",
      "‚úÖ cpu_usage: 49 points, mean=0.3178\n",
      "\n",
      "‚úÖ Calibration experiment completed:\n",
      "  Workload requests: 918\n",
      "  Workload rate: 3.06 req/s\n",
      "  Success rate: 100.0%\n",
      "  Average response time: 0.284s\n",
      "\n",
      "üîç Processing K8s/Istio calibration metrics...\n",
      "  Collected 49 CPU utilization measurements\n",
      "  CPU range: 0.2445 - 0.3756\n",
      "  Collected 49 Istio throughput measurements\n",
      "  Throughput range: 2.73 - 3.42 req/s\n",
      "  Total valid data points: 49 CPU, 49 throughput\n",
      "\n",
      "üìà K8s Service Rate Estimation Results:\n",
      "  Estimated Œº (median): 9.86 req/s\n",
      "  Mean Œº: 9.92 req/s\n",
      "  Standard deviation: 1.01\n",
      "  Coefficient of variation: 0.102\n",
      "  Range: 8.35 - 12.63 req/s\n",
      "  Valid measurements: 49/49\n",
      "  Implied service time: 0.1015 seconds\n",
      "\n",
      "üéâ K8s calibration phase complete\n",
      "Using Œº = 9.86 req/s for K8s validation experiments\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# K8S CALIBRATION CAMPAIGN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "async def run_k8s_calibration_campaign():\n",
    "    \"\"\"\n",
    "    Execute K8s service rate calibration campaign using the NEW working collector.\n",
    "    \n",
    "    Returns:\n",
    "        estimated_mu: Estimated service rate\n",
    "        estimation_stats: Calibration statistics\n",
    "    \"\"\"\n",
    "    print(\"K8s Service Rate Calibration Campaign (NEW COLLECTOR)\")\n",
    "    print(\"=\" * 52)\n",
    "    print(f\"Calibration parameters:\")\n",
    "    print(f\"  Target arrival rate: {CALIBRATION_LAMBDA} req/s\")\n",
    "    print(f\"  Experiment duration: {CALIBRATION_DURATION} seconds\")\n",
    "    print(f\"  Warmup period: {CALIBRATION_WARMUP} seconds\")\n",
    "    print(f\"  Measurement period: {CALIBRATION_DURATION - CALIBRATION_WARMUP} seconds\")\n",
    "    print(f\"  Service endpoint: {mm1_service_url}\")\n",
    "\n",
    "    # System health check before calibration - USING NEW COLLECTOR\n",
    "    collector = K8sPrometheusCollector(PROMETHEUS_URL)\n",
    "    if not collector.health_check():\n",
    "        collector.close()\n",
    "        raise Exception(\"Prometheus not accessible - cannot proceed\")\n",
    "\n",
    "    print(\"\\n‚úÖ Prometheus connectivity confirmed with NEW collector\")\n",
    "    collector.close()\n",
    "\n",
    "    print(\"\\nStarting K8s calibration experiment...\")\n",
    "    print(\"This will take approximately 4 minutes\")\n",
    "    \n",
    "    # Initialize generators and collectors - USING NEW COLLECTOR\n",
    "    async_generator = AsyncWorkloadGenerator(target_url=mm1_service_url, timeout=300.0)\n",
    "    collector = K8sPrometheusCollector(PROMETHEUS_URL)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Generate calibration workload\n",
    "    print(\"\\nüöÄ Running calibration workload...\")\n",
    "    calibration_results = await async_generator.generate_workload(\n",
    "        lambda_rate=CALIBRATION_LAMBDA,\n",
    "        duration=CALIBRATION_DURATION,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(\"\\nüìä Collecting K8s/Istio metrics with NEW collector...\")\n",
    "    \n",
    "    # Collect metrics for steady-state period (skip warmup) - USING NEW METHOD\n",
    "    steady_state_start = start_time + CALIBRATION_WARMUP\n",
    "    calibration_metrics = collector.collect_k8s_metrics(\n",
    "        start_time=steady_state_start,\n",
    "        end_time=end_time,\n",
    "        metrics=['throughput', 'cpu_usage'],  # Core metrics for calibration\n",
    "        step=\"5s\"\n",
    "    )\n",
    "    \n",
    "    collector.close()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Calibration experiment completed:\")\n",
    "    print(f\"  Workload requests: {calibration_results.total_requests}\")\n",
    "    print(f\"  Workload rate: {calibration_results.actual_rate:.2f} req/s\")\n",
    "    print(f\"  Success rate: {calibration_results.success_rate:.1%}\")\n",
    "    print(f\"  Average response time: {calibration_results.average_response_time:.3f}s\")\n",
    "    \n",
    "    # Process calibration data using K8s metrics\n",
    "    print(\"\\nüîç Processing K8s/Istio calibration metrics...\")\n",
    "    \n",
    "    # Extract CPU utilization from K8s metrics (already in 0-1 range)\n",
    "    utilizations = []\n",
    "    if 'cpu_usage' in calibration_metrics:\n",
    "        cpu_data = calibration_metrics['cpu_usage']\n",
    "        utilizations = [v for v in cpu_data.values if v > 0 and v <= 1.0]  # K8s CPU as fraction\n",
    "        print(f\"  Collected {len(utilizations)} CPU utilization measurements\")\n",
    "        if utilizations:\n",
    "            print(f\"  CPU range: {np.min(utilizations):.4f} - {np.max(utilizations):.4f}\")\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è No K8s CPU usage data available\")\n",
    "\n",
    "    # Extract throughput from Istio metrics\n",
    "    throughputs = []\n",
    "    if 'throughput' in calibration_metrics:\n",
    "        throughput_data = calibration_metrics['throughput']\n",
    "        throughputs = [v for v in throughput_data.values if v > 0]\n",
    "        print(f\"  Collected {len(throughputs)} Istio throughput measurements\")\n",
    "        if throughputs:\n",
    "            print(f\"  Throughput range: {np.min(throughputs):.2f} - {np.max(throughputs):.2f} req/s\")\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è No Istio throughput data, using workload generator rate\")\n",
    "        # Fallback to workload generator rate\n",
    "        throughputs = [calibration_results.actual_rate] * len(utilizations)\n",
    "\n",
    "    if utilizations and throughputs:\n",
    "        print(f\"  Total valid data points: {len(utilizations)} CPU, {len(throughputs)} throughput\")\n",
    "        \n",
    "        # Align the arrays (take minimum length)\n",
    "        min_length = min(len(utilizations), len(throughputs))\n",
    "        aligned_utilizations = utilizations[:min_length]\n",
    "        aligned_throughputs = throughputs[:min_length]\n",
    "        \n",
    "        # Estimate service rate using K8s-specific method\n",
    "        estimated_mu, estimation_stats = MM1Theoretical.estimate_service_rate_from_k8s_metrics(\n",
    "            aligned_utilizations, aligned_throughputs\n",
    "        )\n",
    "        \n",
    "        if estimated_mu:\n",
    "            print(f\"\\nüìà K8s Service Rate Estimation Results:\")\n",
    "            print(f\"  Estimated Œº (median): {estimated_mu:.2f} req/s\")\n",
    "            print(f\"  Mean Œº: {estimation_stats['mean_mu']:.2f} req/s\")\n",
    "            print(f\"  Standard deviation: {estimation_stats['std_mu']:.2f}\")\n",
    "            print(f\"  Coefficient of variation: {estimation_stats['cv_mu']:.3f}\")\n",
    "            print(f\"  Range: {estimation_stats['min_mu']:.2f} - {estimation_stats['max_mu']:.2f} req/s\")\n",
    "            print(f\"  Valid measurements: {estimation_stats['valid_measurements']}/{estimation_stats['total_measurements']}\")\n",
    "            \n",
    "            # Implied service time\n",
    "            estimated_service_time = 1.0 / estimated_mu\n",
    "            print(f\"  Implied service time: {estimated_service_time:.4f} seconds\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"\\n‚ùå K8s service rate estimation failed:\")\n",
    "            print(f\"  Error: {estimation_stats.get('error', 'Unknown error')}\")\n",
    "            estimated_mu = 5.0  # Conservative fallback for K8s\n",
    "            estimation_stats = {'error': 'Using fallback value for K8s'}\n",
    "            print(f\"  Using fallback Œº = {estimated_mu} req/s\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Insufficient K8s calibration data - using fallback service rate\")\n",
    "        estimated_mu = 5.0  # Conservative for K8s environment\n",
    "        estimation_stats = {'error': 'Insufficient K8s data'}\n",
    "\n",
    "    print(f\"\\nüéâ K8s calibration phase complete\")\n",
    "    print(f\"Using Œº = {estimated_mu:.2f} req/s for K8s validation experiments\")\n",
    "    \n",
    "    return estimated_mu, estimation_stats\n",
    "\n",
    "# Execute K8s calibration campaign\n",
    "estimated_mu, k8s_calibration_stats = await run_k8s_calibration_campaign()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M/M/1 Validation Experiments\n",
    "\n",
    "Test the estimated service rate by running experiments at different target utilization levels. Each experiment will:\n",
    "\n",
    "**Experiment Design:**\n",
    "- Target different utilization levels (œÅ = 0.2, 0.4, 0.6, 0.8) using estimated Œº\n",
    "- Calculate required arrival rate: Œª = target_utilization √ó estimated_Œº \n",
    "- Run workload for each utilization level with proper cooldown periods\n",
    "- Collect K8s CPU metrics and Istio throughput/response time metrics\n",
    "- Compare measured results with M/M/1 theoretical predictions\n",
    "\n",
    "**Validation Methodology:**\n",
    "- **Theoretical**: Use MM1Theoretical.calculate_metrics(Œª, Œº) for predictions\n",
    "- **Measured**: Collect real metrics using K8sPrometheusCollector\n",
    "- **Comparison**: Statistical correlation and error analysis between theory and practice\n",
    "\n",
    "**Expected Behavior:**\n",
    "- Low utilization (œÅ=0.2): Excellent agreement with theory\n",
    "- Medium utilization (œÅ=0.4-0.6): Good agreement with minor deviations  \n",
    "- High utilization (œÅ=0.8): Potential deviations due to system limitations\n",
    "\n",
    "This validates whether our estimated Œº accurately predicts system behavior under varying loads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# K8S M/M/1 VALIDATION EXPERIMENTS\n# =============================================================================\n\nasync def run_k8s_validation_experiments():\n    \"\"\"\n    Execute M/M/1 validation experiments at different utilization levels.\n    \n    Uses the estimated service rate from calibration to test theoretical predictions\n    against measured K8s/Istio metrics.\n    \n    Returns:\n        k8s_theoretical_predictions: Dict {lambda_rate: theoretical_metrics}\n        k8s_measured_metrics: Dict {lambda_rate: measured_metrics}\n    \"\"\"\n    print(\"K8s M/M/1 Validation Experiments\")\n    print(\"=\" * 33)\n    print(f\"Using estimated Œº = {estimated_mu:.2f} req/s from calibration\")\n    print(f\"Testing {len(TARGET_UTILIZATIONS)} utilization levels: {TARGET_UTILIZATIONS}\")\n    print(f\"Experiment duration: {VALIDATION_DURATION}s each\")\n    print(f\"Warmup period: {VALIDATION_WARMUP}s each\")\n    print(f\"Cooldown between experiments: {VALIDATION_COOLDOWN}s\")\n    \n    total_time = len(TARGET_UTILIZATIONS) * (VALIDATION_DURATION + VALIDATION_COOLDOWN) / 60\n    print(f\"Estimated total time: {total_time:.1f} minutes\")\n    \n    k8s_theoretical_predictions = {}\n    k8s_measured_metrics = {}\n    \n    for i, target_utilization in enumerate(TARGET_UTILIZATIONS):\n        # Calculate required arrival rate for target utilization\n        target_lambda = target_utilization * estimated_mu\n        \n        print(f\"\\n\" + \"=\"*60)\n        print(f\"Validation Experiment {i+1}/{len(TARGET_UTILIZATIONS)}\")\n        print(f\"Target utilization: œÅ = {target_utilization:.1f}\")\n        print(f\"Required arrival rate: Œª = {target_lambda:.2f} req/s\")\n        print(f\"Using service rate: Œº = {estimated_mu:.2f} req/s\")\n        print(\"=\"*60)\n        \n        # Cooldown period (except for first experiment)\n        if i > 0:\n            print(f\"\\n‚è≥ Cooldown period: {VALIDATION_COOLDOWN}s\")\n            print(\"Allowing system to settle before next experiment...\")\n            time.sleep(VALIDATION_COOLDOWN)\n        \n        # Calculate theoretical predictions\n        print(f\"\\nüìä Calculating theoretical M/M/1 predictions...\")\n        theoretical_metrics = MM1Theoretical.calculate_metrics(target_lambda, estimated_mu)\n        k8s_theoretical_predictions[target_lambda] = theoretical_metrics\n        \n        if not theoretical_metrics['stable']:\n            print(f\"‚ö†Ô∏è WARNING: System unstable (Œª ‚â• Œº), skipping experiment\")\n            continue\n            \n        print(f\"‚úÖ Theoretical predictions:\")\n        print(f\"  Utilization: {theoretical_metrics['utilization']:.3f}\")\n        print(f\"  Throughput: {theoretical_metrics['throughput']:.2f} req/s\")\n        print(f\"  Response time: {theoretical_metrics['response_time']:.3f}s\")\n        print(f\"  Queue length: {theoretical_metrics['queue_length']:.2f}\")\n        \n        # Run validation experiment\n        print(f\"\\nüöÄ Running validation experiment...\")\n        print(f\"Generating workload at Œª = {target_lambda:.2f} req/s for {VALIDATION_DURATION}s\")\n        \n        async_generator = AsyncWorkloadGenerator(target_url=mm1_service_url, timeout=300.0)\n        collector = K8sPrometheusCollector(PROMETHEUS_URL)\n        \n        start_time = time.time()\n        \n        # Generate workload\n        workload_results = await async_generator.generate_workload(\n            lambda_rate=target_lambda,\n            duration=VALIDATION_DURATION,\n            verbose=False\n        )\n        \n        end_time = time.time()\n        \n        print(f\"‚úÖ Workload completed:\")\n        print(f\"  Target rate: {target_lambda:.2f} req/s\")\n        print(f\"  Actual rate: {workload_results.actual_rate:.2f} req/s\")\n        print(f\"  Success rate: {workload_results.success_rate:.1%}\")\n        print(f\"  Total requests: {workload_results.total_requests}\")\n        print(f\"  Avg response time: {workload_results.average_response_time:.3f}s\")\n        \n        # Collect K8s/Istio metrics (skip warmup period)\n        print(f\"\\nüìä Collecting K8s/Istio metrics...\")\n        steady_state_start = start_time + VALIDATION_WARMUP\n        \n        validation_metrics = collector.collect_k8s_metrics(\n            start_time=steady_state_start,\n            end_time=end_time,\n            metrics=['throughput', 'cpu_usage'],  # Same as calibration - WORKING!\n            step=METRICS_STEP\n        )\n        \n        collector.close()\n        \n        # Process measured metrics\n        print(f\"üìà Processing measured metrics...\")\n        measured_metrics = {\n            'lambda_rate': target_lambda,\n            'utilization': None,\n            'throughput': None,\n            'response_time': None,\n            'response_time_client': workload_results.average_response_time,\n            'response_time_istio': None,\n            'response_time_source': 'client-side',  # Default\n            'success_rate': workload_results.success_rate,\n            'total_requests': workload_results.total_requests,\n            'actual_rate': workload_results.actual_rate\n        }\n        \n        # Extract CPU utilization (K8s native metrics)\n        if 'cpu_usage' in validation_metrics and validation_metrics['cpu_usage'].values:\n            cpu_values = [v for v in validation_metrics['cpu_usage'].values if v > 0 and v <= 1.0]\n            if cpu_values:\n                measured_metrics['utilization'] = np.mean(cpu_values)\n                print(f\"  K8s CPU utilization: {measured_metrics['utilization']:.3f} ({len(cpu_values)} samples)\")\n            else:\n                print(f\"  ‚ö†Ô∏è No valid K8s CPU utilization data\")\n        else:\n            print(f\"  ‚ö†Ô∏è No K8s CPU usage metrics available\")\n        \n        # Extract throughput (Istio metrics)\n        if 'throughput' in validation_metrics and validation_metrics['throughput'].values:\n            throughput_values = [v for v in validation_metrics['throughput'].values if v > 0]\n            if throughput_values:\n                measured_metrics['throughput'] = np.mean(throughput_values)\n                print(f\"  Istio throughput: {measured_metrics['throughput']:.2f} req/s ({len(throughput_values)} samples)\")\n            else:\n                print(f\"  ‚ö†Ô∏è No valid Istio throughput data, using workload rate\")\n                measured_metrics['throughput'] = workload_results.actual_rate\n        else:\n            print(f\"  ‚ö†Ô∏è No Istio throughput metrics, using workload rate\")\n            measured_metrics['throughput'] = workload_results.actual_rate\n        \n        # For response time, since we're not collecting Istio response_time_avg, use client-side\n        measured_metrics['response_time'] = workload_results.average_response_time\n        print(f\"  Response time (client-side): {measured_metrics['response_time']:.3f}s\")\n        \n        # Store measured results\n        k8s_measured_metrics[target_lambda] = measured_metrics\n        \n        # Compare with theoretical predictions\n        print(f\"\\nüìã Experiment {i+1} Summary:\")\n        print(f\"  Theoretical vs Measured:\")\n        if measured_metrics['utilization']:\n            util_error = abs(theoretical_metrics['utilization'] - measured_metrics['utilization']) / theoretical_metrics['utilization'] * 100\n            print(f\"    Utilization: {theoretical_metrics['utilization']:.3f} vs {measured_metrics['utilization']:.3f} ({util_error:.1f}% error)\")\n        \n        if measured_metrics['throughput']:\n            tp_error = abs(theoretical_metrics['throughput'] - measured_metrics['throughput']) / theoretical_metrics['throughput'] * 100\n            print(f\"    Throughput: {theoretical_metrics['throughput']:.2f} vs {measured_metrics['throughput']:.2f} req/s ({tp_error:.1f}% error)\")\n        \n        if measured_metrics['response_time']:\n            rt_error = abs(theoretical_metrics['response_time'] - measured_metrics['response_time']) / theoretical_metrics['response_time'] * 100\n            print(f\"    Response time: {theoretical_metrics['response_time']:.3f} vs {measured_metrics['response_time']:.3f}s ({rt_error:.1f}% error)\")\n    \n    print(f\"\\nüéâ K8s M/M/1 validation experiments completed!\")\n    print(f\"‚úÖ Completed {len(k8s_measured_metrics)} validation experiments\")\n    print(f\"üìä Ready for validation analysis and plotting\")\n    \n    return k8s_theoretical_predictions, k8s_measured_metrics\n\n# Execute K8s validation experiments\nk8s_theoretical_predictions, k8s_measured_metrics = await run_k8s_validation_experiments()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Results Analysis and Visualization\n",
    "\n",
    "Analyze the M/M/1 validation results by comparing theoretical predictions with measured K8s/Istio metrics.\n",
    "\n",
    "**Analysis Components:**\n",
    "- **Correlation Analysis**: Statistical correlation between theoretical and measured values\n",
    "- **Error Quantification**: Mean Absolute Relative Errors (MARE) for each metric type\n",
    "- **Visual Comparison**: Side-by-side plots of theory vs measurements\n",
    "- **Source Analysis**: Comparison of client-side vs Istio service mesh response times\n",
    "\n",
    "**Key Metrics Compared:**\n",
    "- **Throughput**: Theoretical Œª vs Istio request rate measurements\n",
    "- **Response Time**: Theoretical E[T] vs measured latency (client and/or Istio)\n",
    "- **Utilization**: Theoretical œÅ vs K8s CPU utilization metrics\n",
    "\n",
    "**Expected Insights:**\n",
    "- Model accuracy across different utilization levels\n",
    "- Impact of cloud-native observability on measurement precision\n",
    "- Identification of system behavior deviations from theoretical predictions\n",
    "- Validation of service rate estimation methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# K8S VALIDATION RESULTS ANALYSIS AND PLOTTING\n",
    "# =============================================================================\n",
    "\n",
    "# Import K8s-specific plotting functions\n",
    "from k8s_validation_plots import (\n",
    "    plot_k8s_validation_analysis, \n",
    "    calculate_k8s_validation_statistics,\n",
    "    plot_k8s_experiment_timeline\n",
    ")\n",
    "\n",
    "def analyze_k8s_validation_results():\n",
    "    \"\"\"\n",
    "    Comprehensive analysis of K8s M/M/1 validation results.\n",
    "    \n",
    "    Performs statistical analysis and creates visualization plots comparing\n",
    "    theoretical M/M/1 predictions with measured K8s/Istio metrics.\n",
    "    \"\"\"\n",
    "    print(\"K8s M/M/1 Validation Results Analysis\")\n",
    "    print(\"=\" * 37)\n",
    "    print(f\"Analyzing {len(k8s_measured_metrics)} validation experiments\")\n",
    "    print(f\"Estimated service rate: Œº = {estimated_mu:.2f} req/s\")\n",
    "    print(f\"Tested utilization levels: {TARGET_UTILIZATIONS}\")\n",
    "    \n",
    "    # Validate that we have data to analyze\n",
    "    if not k8s_theoretical_predictions or not k8s_measured_metrics:\n",
    "        print(\"‚ùå No validation data available for analysis\")\n",
    "        return\n",
    "    \n",
    "    # 1. Generate comprehensive validation plots\n",
    "    print(f\"\\nüìä Generating K8s validation plots...\")\n",
    "    try:\n",
    "        plot_k8s_validation_analysis(\n",
    "            k8s_theoretical_predictions, \n",
    "            k8s_measured_metrics, \n",
    "            estimated_mu\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Plotting error: {e}\")\n",
    "    \n",
    "    # 2. Calculate statistical validation metrics\n",
    "    print(f\"\\nüìà Computing statistical validation metrics...\")\n",
    "    try:\n",
    "        k8s_validation_stats = calculate_k8s_validation_statistics(\n",
    "            k8s_theoretical_predictions, \n",
    "            k8s_measured_metrics\n",
    "        )\n",
    "        \n",
    "        # Display detailed statistical analysis\n",
    "        print(f\"\\nüìã K8s Statistical Validation Summary:\")\n",
    "        print(f\"=\" * 37)\n",
    "        \n",
    "        if 'error' not in k8s_validation_stats:\n",
    "            print(f\"Experiments analyzed: {k8s_validation_stats['experiments_count']}\")\n",
    "            \n",
    "            # Correlation analysis\n",
    "            print(f\"\\nüîó Correlation Coefficients (K8s/Istio vs Theory):\")\n",
    "            correlation_metrics = ['throughput_corr', 'response_time_corr', 'utilization_corr']\n",
    "            for metric in correlation_metrics:\n",
    "                if metric in k8s_validation_stats:\n",
    "                    corr = k8s_validation_stats[metric]\n",
    "                    p_val = k8s_validation_stats.get(metric.replace('_corr', '_p_value'), 'N/A')\n",
    "                    metric_name = metric.replace('_corr', '').replace('_', ' ').title()\n",
    "                    print(f\"  {metric_name}: r = {corr:.3f} (p = {p_val})\")\n",
    "            \n",
    "            # Error analysis\n",
    "            print(f\"\\nüìè Mean Absolute Relative Errors (MARE):\")\n",
    "            error_metrics = ['throughput_mae', 'response_time_mae', 'utilization_mae']\n",
    "            for metric in error_metrics:\n",
    "                if metric in k8s_validation_stats:\n",
    "                    error = k8s_validation_stats[metric]\n",
    "                    metric_name = metric.replace('_mae', '').replace('_', ' ').title()\n",
    "                    print(f\"  {metric_name}: {error:.1f}%\")\n",
    "            \n",
    "            # Overall assessment\n",
    "            print(f\"\\nüéØ Overall K8s Model Assessment:\")\n",
    "            print(f\"  Assessment: {k8s_validation_stats['assessment']}\")\n",
    "            print(f\"  Minimum correlation: {k8s_validation_stats['min_correlation']:.3f}\")\n",
    "            print(f\"  Maximum error: {k8s_validation_stats['max_error']:.1f}%\")\n",
    "            \n",
    "            # Response time source analysis\n",
    "            if 'response_time_sources' in k8s_validation_stats:\n",
    "                print(f\"\\nüì° Response Time Measurement Sources:\")\n",
    "                sources = k8s_validation_stats['response_time_sources']\n",
    "                for source, count in sources.items():\n",
    "                    print(f\"  {source}: {count} experiments\")\n",
    "        else:\n",
    "            print(f\"‚ùå Statistical analysis failed: {k8s_validation_stats['error']}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Statistical analysis error: {e}\")\n",
    "    \n",
    "    # 3. Generate experiment timeline plot\n",
    "    print(f\"\\nüìà Generating experiment timeline...\")\n",
    "    try:\n",
    "        plot_k8s_experiment_timeline(\n",
    "            k8s_measured_metrics,\n",
    "            title=\"K8s M/M/1 Validation Experiment Timeline\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Timeline plotting error: {e}\")\n",
    "    \n",
    "    # 4. Detailed per-experiment comparison\n",
    "    print(f\"\\nüìä Detailed Per-Experiment Analysis:\")\n",
    "    print(\"=\" * 37)\n",
    "    \n",
    "    for lambda_rate in sorted(k8s_measured_metrics.keys()):\n",
    "        theoretical = k8s_theoretical_predictions.get(lambda_rate, {})\n",
    "        measured = k8s_measured_metrics[lambda_rate]\n",
    "        \n",
    "        target_util = lambda_rate / estimated_mu\n",
    "        print(f\"\\nüî¨ Experiment: Œª = {lambda_rate:.2f} req/s (œÅ = {target_util:.2f})\")\n",
    "        \n",
    "        # Throughput comparison\n",
    "        if theoretical.get('throughput') and measured.get('throughput'):\n",
    "            th_tp = theoretical['throughput']\n",
    "            ms_tp = measured['throughput']\n",
    "            tp_error = abs(th_tp - ms_tp) / th_tp * 100\n",
    "            print(f\"  Throughput: {th_tp:.2f} ‚Üí {ms_tp:.2f} req/s ({tp_error:.1f}% error)\")\n",
    "        \n",
    "        # Response time comparison\n",
    "        if theoretical.get('response_time') and measured.get('response_time'):\n",
    "            th_rt = theoretical['response_time']\n",
    "            ms_rt = measured['response_time']\n",
    "            rt_error = abs(th_rt - ms_rt) / th_rt * 100\n",
    "            rt_source = measured.get('response_time_source', 'unknown')\n",
    "            print(f\"  Response time: {th_rt:.3f} ‚Üí {ms_rt:.3f}s ({rt_error:.1f}% error, {rt_source})\")\n",
    "        \n",
    "        # Utilization comparison\n",
    "        if theoretical.get('utilization') and measured.get('utilization'):\n",
    "            th_util = theoretical['utilization']\n",
    "            ms_util = measured['utilization']\n",
    "            util_error = abs(th_util - ms_util) / th_util * 100\n",
    "            print(f\"  Utilization: {th_util:.3f} ‚Üí {ms_util:.3f} ({util_error:.1f}% error)\")\n",
    "        \n",
    "        # Success rate\n",
    "        success_rate = measured.get('success_rate', 0)\n",
    "        if success_rate < 0.99:\n",
    "            print(f\"  ‚ö†Ô∏è Success rate: {success_rate:.1%} (< 99%)\")\n",
    "    \n",
    "    # 5. Key insights and recommendations\n",
    "    print(f\"\\nüí° K8s Validation Insights:\")\n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "    # Analyze utilization levels performance\n",
    "    high_util_issues = []\n",
    "    excellent_agreement = []\n",
    "    \n",
    "    for lambda_rate in sorted(k8s_measured_metrics.keys()):\n",
    "        target_util = lambda_rate / estimated_mu\n",
    "        measured = k8s_measured_metrics[lambda_rate]\n",
    "        theoretical = k8s_theoretical_predictions.get(lambda_rate, {})\n",
    "        \n",
    "        if measured.get('success_rate', 1.0) < 0.99:\n",
    "            high_util_issues.append(f\"œÅ={target_util:.1f}\")\n",
    "        \n",
    "        # Check if all metrics have low error\n",
    "        low_error_count = 0\n",
    "        for metric in ['throughput', 'response_time', 'utilization']:\n",
    "            th_val = theoretical.get(metric)\n",
    "            ms_val = measured.get(metric)\n",
    "            if th_val and ms_val:\n",
    "                error = abs(th_val - ms_val) / th_val * 100\n",
    "                if error < 15:  # Less than 15% error\n",
    "                    low_error_count += 1\n",
    "        \n",
    "        if low_error_count >= 2:\n",
    "            excellent_agreement.append(f\"œÅ={target_util:.1f}\")\n",
    "    \n",
    "    print(f\"‚úÖ Excellent model agreement: {', '.join(excellent_agreement) if excellent_agreement else 'None'}\")\n",
    "    print(f\"‚ö†Ô∏è High utilization issues: {', '.join(high_util_issues) if high_util_issues else 'None'}\")\n",
    "    \n",
    "    # Cloud-native benefits\n",
    "    print(f\"\\nüöÄ Cloud-Native Observability Benefits:\")\n",
    "    istio_measurements = sum(1 for m in k8s_measured_metrics.values() \n",
    "                           if m.get('response_time_source') == 'Istio service mesh')\n",
    "    total_measurements = len(k8s_measured_metrics)\n",
    "    \n",
    "    if istio_measurements > 0:\n",
    "        print(f\"  Istio service mesh metrics: {istio_measurements}/{total_measurements} experiments\")\n",
    "        print(f\"  Native K8s CPU monitoring: CPU utilization without application instrumentation\")\n",
    "        print(f\"  Service mesh benefits: Server-side response time measurements\")\n",
    "    \n",
    "    print(f\"\\nüéâ K8s M/M/1 validation analysis complete!\")\n",
    "\n",
    "# Execute comprehensive validation analysis\n",
    "analyze_k8s_validation_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}